一些碎碎念


（2025.04.12）
今日完成内容：
1.修改了模型的位置
2.移除了faster whisper模型的使用，完全依靠funasr模型
3.调整了静音判定时间为3秒
4.在静音判定完成后自动将识别内容输入到对话框
5.完成了聊天框的初步设计，但是外观问题还有十分多的内容需要处理
未完成内容：
感觉录音转文字效果还是不太好，但先暂时放一边吧，先把下面的模块完成了再说。
需要添加静音判定结束后自动停止录音，关闭麦克风功能
麦克风关闭流程需要优化，目前关闭速度过慢（大致优化流程在元宝置顶中，等待后续进行实践）



（2025.04.11）
今日完成内容：
1.更改asr模块，从sincevoice改为fun asr，因为他还集成了vad和标点预测功能，更适合纯中文，准确率更高（但目前还没更新模型位置，会显示查找不到模型）
2.添加了点击麦克风按钮关闭功能
3.安装git，创建git仓库（原因：由于有时候会不小心瞎改导致以前做了的内容出错，这时候可能需要进行回滚操作，也需要保存项目到线上的功能）
我受不了了，之前在公司用的内容全还给公司了，这玩意搞的我想死，创建一个git仓库搞了我两个小时的时间，我要崩溃了！！！


（2025.04.10）
今日完成内容：
1.完成后端的建立
2.连通前后端
3.在点击麦克风的时候可以进行收音，然后结束后将音频转化为文字显示在输入框中。
4.增加了说完话后自动静音功能（但这个功能效果不太好，还需要优化）
未完成内容：声音的检测转化效果一般，需要修改。
未完成内容：
收音效果还需要进行调整
再次点击麦克风时关闭收音
自动静音后关闭麦克风（还有按钮）
下载好了FFmpeg7，等待更新，目前是4



（2025.04.09）
今日完成内容：
1.完成输入框和模型的关闭逻辑关联
2.完成鼠标滚轮缩放
遗留问题：
1.当模型放到过大或者过小的时候，对话框距离还是有点不合适，优先级：较低
2.在模型缩放过程中，会有一些抖动，有些影响感官，优先级：较低
正在进行内容：
创建后端服务器，将前端和后端连起来，仅使用一个main文件同时启动前后端，然后在前端对后端的asr模块进行测试，确保真正连通


（2025.04.08）
今日完成内容：
1.重构live2d窗口代码，建立父子窗口关系，为后续添加各种窗口提供便利
2.创建对话框窗口，在旁边加上语音输入和发送图标，完成一部分ui建设
3.锚定对话框与模型，能够跟随模型进行移动
4.创建调试功能，能够通过调试功能检查各窗口组件之间的层级关系和坐标位置
5.调整对话框初始化大小和后续增减文字的窗口变化情况
遗留问题：
1.表情切换还是没有实现，虽然已经有了初步思路，等待后续处理
2.输入框初始化后需要移动一次模型才能选中进行输入，算是一个小bug，但不影响使用，优先级：较低。
3.输入框在选中输入文字后高度会降低2px 目前原因未知，调试的时候输入框的坐标和高度都没有发生变化。怀疑是样式问题，全做完后再进行排查。算是一个可有可无的优化，优先级：极低
4.输入框在高度降低后会遮挡提示文字下面一小部分（如：请输入文字）目前原因未知，等后期排查优化，优先级：极低
后续功能安排：
1.明天首先将模型和输入框关闭逻辑相关联，实现关闭模型的同时关闭输入框
2.其次实现鼠标滚轮缩放功能，缩放的同时需要保持输入框的大小，距离不变
3.创建后端，将前后端打通，然后在后端连上asr模型，进行初步的接收声音-识别文字-文字输出测试




然后现在在用cursor从头开始一点点搞，先搞了live2d，然后后面的问题后面再说吧，先搞搞看看吧。





头都大了，搞了半天才发现那个倒霉玩意不是个开源的项目，想改都没法改，好吧，那就只能换个项目试试了。然后找了个项目更是大怨种，呀呀呸的写代码不写注释，是真的一点都看不懂，然后设置还难的跟鬼一样，一点都不好配置，可读性差的要死。用ai折腾了半天，辛辛苦苦把他的那些模型api转成了本地，然后搞了半天还没法用，响应慢的要命，最后算了，还是自己老老实实自己做吧



声音的敏感度不行，不知道是我没设置好还是怎么回事，更新到6.11然后再看看配置视频再说吧，实在不行的话收音模式也要更改才行


目前选择依赖项目七，在项目四的基础上进行调整
具体调整需要等下载下来后再做决定
至少需要的几个功能必须要有，具体功能参考readme
需要增加一个屏幕文字识别功能，然后进行点击。如：点击屏幕上的网易云音乐文字（支持点击，长按，双击等，识别完文字后，列出方框进行询问：已在屏幕上找到以下，请问你要选第几个？）


如果三个模型都部署在本机上，它们启动时都会提供一个端口号，然后就需要通过端口号进行数据交互，我们要做的就是写一个端口号间数据交互的脚本



现在开始全部推翻重新来
先来一波市场调研，然后再进行考察
项目一：
AI+live2d看板娘浏览器助手，实现模型切换和页面内容总结
开源地址：PublicLive2dPlug/PublicLive2dAIPlug at main · Vita0519/PublicLive2dPlug（github）
功能：live2d模型展示，只能页面总结，多模型支持，高度自定义，便捷操作，api设置

项目二：
Live2D For C++(Qt)实现二次元桌宠--BV1TtkHYpEDA
https://github.com/Misakiotoha/Live2D_For_C-Qt-OpenGL-

项目三：
【开源AI桌宠】你的下一个人工智能，何必是网页--BV1E3XWYMErS
开源地址：https://github.com/HeavyNotFat/Agentic-AI-Desktop-Pet
下载地址：https://github.com/HeavyNotFat/Agentic-AI-Desktop-Pet/releases
官网：http://nekocode.top
功能：live2d模型展示，ai语音（gsv），大语言模型，扩展接口

项目四：
【全球第一个AI-Agent桌宠】芙宁娜教你如何正确使用最强Agent桌宠--BV1nS42197pj
https://pan.quark.cn/s/dd6d8cc5f609
功能：聊天，问答，联网，live2d人物模型，执行计算机操作

项目五：
五分钟部署一个有长期记忆和表情动作ai桌宠，ZcChat安装教程2.0--BV1hA9SYYEbb
https://github.com/Zao-chen/ZcChat
功能：语音输入输出，语音唤醒，操控电脑，制作角色（只是jpg，不是live2d），自定义llm

项目六：
It's Agent Time! 你的本地智能代理人时间到 Nath UI 4.1 整合包 重磅更新--BV1259bYeE6P
优点：写论文的时候可以参考流程图和使用思路

项目七：
开源AI桌宠2.2更新，1分钟即可上手，手搓中文脚本给AI，让大模型做更多的事情，完成简易agent--BV1t8ePeBE2m
https://dd-mastert.github.io/2024/08/15/2024.8.15-2/
功能：可以参考他的电脑操作思路



安装 webrtcvad 疯狂出错，说是我本地没有能够编译的环境，搞了vs2019后还是不行
最后居然是在csdn上找到人家已经编译好了的包，然后直接解压缩到虚拟环境中解决的
那个编译好的包的下载地址还被墙了，就离谱
然后下载下来后发现还是跑不动，一查才发现要在电脑上编译一遍才行
后面重新下载了vs2022，用它专门那个x64 native什么的cmd才正常下载，重新编译成功了
然后才能正常使用




首先，做好了一个前后端，前端可以通过按钮发送请求给后端接受

语音输入：在前端添加麦克风输入功能，使用WebRTC捕获音频，并将音频数据发送到后端。
语音识别：在后端调用ASR模型，将音频数据转换为文本。
文本生成：在后端调用LLM模型，生成响应文本。
语音合成：在后端调用TTS模型，将文本转换为语音，并返回给前端播放。

失败，失败原因：阿里的asr模型没有下载部署，需要另行下载




我需要做一个基于Python的语音助手设计与实现，界面需要做成一个可以在电脑桌面上显示的live2D模型，
而且这个模型需要支持直接套用VTuberStudio的模型文件。右键这个桌面的live2D模型需要可以打开一个完整的设置界面。
其中使用ASR+LLM+TTS串联形式来搭建本地的语音交互助手，采用阿里开源SenceVoice作为ASR模型，tts需要使用GPT-SoVITS的模型。
后台需要可以接入部署在电脑上的第三方大语言模型比如说deepseek-r1:14b，或者ollama。帮我设计这个项目的技术架构




听了网友劝，不用pycharm了，用vscode试试




可以提供参考的项目
搭建自己的语音对话大模型 | ASR+LLM+TTS串联--------------https://github.com/ABexit/ASR-LLM-TTS
开发了一个越聊越懂你的AI女友 | 开源｜腾讯云AI代码助手----https://github.com/mewamew/nana
训练一个AI桌宠 创造出你喜欢的角色 你想做的，都能实现-----https://github.com/morettt/my-neuro
开源AI女友安装教学 [Open-LLM-VTuber v0.2.4]------------https://github.com/t41372/Open-LLM-VTuber





asr试了谷歌的，结果一直报错
语音服务请求失败：recognition connection failed: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。
一直连不上，问ai找解决方法也没找到，然后放弃了
然后跑去尝试离线的sphinx，但是发现这玩意不管是中文还是英文转化都有点大病，根本没法正常使用
然后打算试一下vosk，结果还没开始尝试，找到破站说阿里的比较好用
明天去试试阿里的这东西
而且在破站找了找才知道，像我现在看到一个就下一个依赖项是有那么点大病的，最好还是搞一个虚拟环境
我终于知道为啥我c盘会爆炸了，估计是之前搞的一堆乱七八糟的环境，然后还没清理那种
真得给这个鬼玩意安排一个虚拟环境





要下载以下第三方库，然后进行导入
pip install speechrecognition pyttsx3 pyautogui selenium flask sqlalchemy
pip install wolframalpha wikipedia winshell pyjokes twilio beautifulsoup4 tk

下载完成后验证一下
import speech_recognition as sr
import pyttsx3
import pyautogui
from selenium import webdriver
from flask import Flask
from sqlalchemy import create_engine
print("所有库导入成功！"