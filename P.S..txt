一些碎碎念


姑且算是备忘录：明天进行内容
如果想要做llm模块的话，做短期记忆系统，意图识别系统
开发tts模块的基础功能，，然后实现不同情绪的语音合成，
然后重新回到表情模块，彻底完成表情切换功能，然后开始进行表情识别的实现
然后开始跟着记录里面的顺序进行一个个实现
可以通过ai进行检查进度，话术如下：
根据这两个实现指导文档，查看整个项目
告诉我目前llm模块进度到了什么程度，接下来还有什么内容没有完成


(2025.04.25)
1.将HTTP请求改为异步方式
2.分离LLM生成和TTS处理
3.使用Qt的信号槽机制处理异步响应
4.使用线程池处理TTS
5.添加进度指示器，让用户知道处理状态
6.实现取消机制，允许用户取消正在进行的处理
7.优化信息传递流程，在ui传递给信息给llm后，llm同时传递给ui和tts，tts只传递音频
8.实现tts根据文本生成的感情来选择对应感情
9.传递给tts的文本省去前面的情绪标签和中间的括号
10.修改情绪映射分类，使分类更为准确
11.给发送图标添加新功能：回车发送，shift+回车换行
12.增加限制词，上限为250字
13.优化播放线程，给音频提供更长的播放时间，增加容错率（实际上还是无法完全避免在音频播放完成前关闭线程）
ps:我吐血了，怎么会有人用get调用post接口的东西啊（恼）
未完成内容：
还是先播放完语音才出文字，这一点还需要改
气泡不知道啥时候被删了，还要重新加上，然后tts生成的内容丢里面



（2025.04.25）
1.对tts模块增加充分的日志记录，便于定位问题存在
2.已经完成实时播放功能，现在可以一边生成语音一边进行播放了
3.优化音频播放功能，在全部播放完成后才结束进程。
4.增加回调函数，使语音和文字同步出现，更改系统架构，从单线程变为多线程，实现并行处理（增加了，但实际上还是没完全实现）（在处理多线程问题中耗时过多，并且没有任何实际上的进展）
遇到问题：还是没有正确处理好多线程之间的运行，导致模型一回复就卡死



（2025.04.24）
1.将后端启动程序集成到main中
2.将tts模块的api集成到后端server文件中
3.将tts模块和llm模块相连接，让他可以根据回复生成语音
4.对生成的语音文件进行管理，保存在data文件夹，增加命名规则
5.建立日志文件，进行记录，日志按照天为单位进行记录（实际上并没有记录成功，后期再来排查问题）
6.将接口的默认生成从完整改成流式
7.更改了生成保存逻辑，生成语音用流式，保存文件用完整
8.修改api模型的问题，让api模型也能够使用tts功能
9.将numpy的冲突问题解决，卸载2.x版本并且安装1.26.4版本
出现一个问题：
有可能会因为一次性生成的文本过多然后导致程序卡住，后续想办法解决，看是限制文本生成字数还是改变逻辑
待做内容：
每次启动的时候默认清空一次语音文件夹（可要可不要）
在生成语音的时候自动播放出来



（2025.04.20）
1.完成了deepseek的api配置，但是目前不能联网搜索
2.幻日的api配置还没完成，连接不上，需要等明天再问问大佬怎么做，但其实感觉好像d老师够用了
3.增加了选项可以切换模型，默认使用本地模型
4.增加了情绪模块，细分出16种情绪，然后通过情绪映射表归类为4种
5.修改了base文件，对本地模型和api模型的代码进行重构，将本地模型和api模型的配置统一
6.对情绪判断进行细分，增加了权重系统，联系上下文判断，添加了情绪优先级
遗留问题：
1.在大语言模型正在生成回复的时候，人物模型会卡住，不会活动，这个问题比较严重，需要优化，优先级：高
2.对于情绪的分类虽然还是不太准确，但勉强能用，不是特别严重，优先级：低
3.没有设置默认使用api回复，默认还是使用本地模型，这个看心情吧，好像也不是特别有必要改
4.api模型目前无法联网搜索，这个问题很大，会对后面agent模块造成较大影响，优先级：极高

（2025.04.17）
今日完成内容：
1.将cuda从11.8更新到12.1，下载安装cudnn模块，成功下载安装pytorch和其相关的依赖
2.成功将本地llm模型连上
3.完成了对对话历史管理逻辑，上下文历史，提示词设置的修改
4.增加了一大片关于llm的历史日志监控，可以更好地排查问题出处，保持llm模型的稳定
未完成内容：
1.未来有时间将api接口也写完整，然后在菜单中添加选项，是选择本地模型还是api接口
2.api的话可以参考使用两个，一个是d老师的api，在里面还有十块钱余额没用完。另一个是幻宙api，有时间看看他的模型价格，免费模型和高性能模型分别是什么价，感觉那个效果不错，很棒
3.给对话框的发送加一个回车发送的功能，不然每次点起来太费劲了
4.由于更改了pytorch相关的内容，好像导致前面的numpy的版本问题，导致无法使用语音功能，后期记得进行修改
5.FFmpeg这方面的内容，需要使用ffmpeg进行语音的转换，但是目前这方面FFmpeg有报错，后续在进行修改



（2025.04.16）
今日完成内容:
初步完成了llm模块的内容，但由于没有可以支持gpu运行的pytorch，
所以暂时没法对模块进行测试
后续等下载安装完成后会进行尝试，如果失败了再进行优化。




（2025.04.15）
捋了一遍llm模块的实现方式和实现步骤，初步先使用qwen 1.5b的丐版进行实现，
后续如果硬件不支持再换成阿里云服务器进行白嫖。
具体事项查看llm模块实现的两个文档
如果找不到文件可以在git中show log


（2025.04.13）
今日完成内容：
1.在人物头顶生成气泡，没消息的时候显示。。。
2.在聊天框没有打开的时候输入文本也有记录，通过添加消息队列实现
3.背景颜色可配置，设置为浅紫色，边框可配置，目前是细边框
4.气泡文字出现实现动画生成，一段段文字出现，全出完后等待5s消失
遗留问题：
1.气泡最多显示3-4行字，超框的话只会停留在当前位置，不会刷新文字或者往下滚动（暂未进行优化，优化方式参考与小号聊天记录，关键词：气泡中的内容）



（2025.04.12）
今日完成内容：
1.增加聊天窗口，在菜单中可以打开/关闭窗口，置顶/取消置顶窗口，调整字体大小
2.聊天框支持配置颜色，图标，标题，角色名字，名字颜色
3.关闭窗口不会影响模型，可重新打开关闭模型连带关闭窗口
4.可以对窗口进行缩放操作
遗留问题：
1.在调整了字体大小后需要再次移动模型才能进行输入，比较影响感官，后续看情况优化，优先级：较低

第二版聊天框设计：
现在，我想制作一个文本交互的窗口来帮助用户和人物模型进行对话，他大概长这个样子：一个长方形的聊天框，在顶部有着“聊天框”三个字居中放置，边框呈现灰色，文字在对话框中间显示，用户发送的信息显示名字为“我”（我：这是一个测试信息），人物模型发送的消息显示的名字支持配置，初始化配置名字为“久久”（久久：我收到了你的测试信息）
详细要求如下：
1.对话框需要和人物模型相互独立，在一个新的窗口中实现，移动对话框和移动模型不会相互影响
2.在对话框的右上角有一个“x”的图标可以将对话框关闭
3.右键点击人物模型打开菜单，在菜单中可以选择“打开/关闭对话框”
4.对话框默认置顶，但在菜单中可以选择“是否置顶对话框”
5.对话框窗口支持在边框进行放大缩小，更改长宽功能（类似网页窗口或市面上各种窗口）
6.在窗口大小更改的时候，其中文字长度支持自适应变化
7.在人物模型下方的输入框中输入的内容点击发送后会显示到对话框中，显示为“我”发送的内容



（2025.04.12）
今日完成内容：
1.修改了模型的位置
2.移除了faster whisper模型的使用，完全依靠funasr模型
3.调整了静音判定时间为3秒
4.在静音判定完成后自动将识别内容输入到对话框
5.完成了聊天框的初步设计，但是外观问题还有十分多的内容需要处理
未完成内容：
感觉录音转文字效果还是不太好，但先暂时放一边吧，先把下面的模块完成了再说。
需要添加静音判定结束后自动停止录音，关闭麦克风功能
麦克风关闭流程需要优化，目前关闭速度过慢（大致优化流程在元宝置顶中，等待后续进行实践）

初版聊天框设计：
如果我想在人物模型头上添加一个背景，边框都是透明的聊天框，然后以类似微信对话的那种气泡的形式进行对话。我期望中的效果是用户说的话是白色的气泡，处于聊天框的左边。人物模型说的话是绿色的气泡，处于聊天框的右边。应该怎么做？
可以参考以下思路，但如果有更好的实现方法也可以进行分析对比然后告诉我，让我进行选择
1.使用QWidget来作为聊天容器，保证聊天框无边框，透明且始终置顶
2.继承QLabel实现可动态调整的气泡控件，根据消息方向（左/右）切换对应样式，自适应大小，支持缩放，
3.使用QVBoxLayout垂直排列气泡，结合QScrollArea实现滚动显示
4.聊天框使用和输入框一样的逻辑，对模型进行连接。需要做到连接模型窗口的移动信号和关闭信号，做到在模型移动的时候始终在模型头上，模型关闭的时候跟随一起关闭。
5.添加ignore事件实现透明穿透点击，避免遮挡下方控件。
6.添加消息函数，让用户在下面输入框点击发送后可以将输入框的内容发送到聊天框并且显示出来。
7.聊天框需要添加一个红色虚线边框来显示边框位置，需要支持显示或隐藏功能。具体实现参考模型的点击区域显示
8.聊天框需要添加一个自定义调整宽度，调整高度功能，具体实现参考点击区域的范围调整。
9.在右键点击模型打开菜单的窗口增加一个聊天框选项，在聊天框选项的二级菜单中包含：显示/隐藏聊天框区域，调整宽度，调整高度。
强调！！在实现的过程中不要移除下方的输入框和按钮逻辑，我需要通过下面的输入框来进行输入。头上的聊天框只用于显示对话内容。


（2025.04.11）
今日完成内容：
1.更改asr模块，从sincevoice改为fun asr，因为他还集成了vad和标点预测功能，更适合纯中文，准确率更高（但目前还没更新模型位置，会显示查找不到模型）
2.添加了点击麦克风按钮关闭功能
3.安装git，创建git仓库（原因：由于有时候会不小心瞎改导致以前做了的内容出错，这时候可能需要进行回滚操作，也需要保存项目到线上的功能）
我受不了了，之前在公司用的内容全还给公司了，这玩意搞的我想死，创建一个git仓库搞了我两个小时的时间，我要崩溃了！！！


（2025.04.10）
今日完成内容：
1.完成后端的建立
2.连通前后端
3.在点击麦克风的时候可以进行收音，然后结束后将音频转化为文字显示在输入框中。
4.增加了说完话后自动静音功能（但这个功能效果不太好，还需要优化）
未完成内容：
收音效果还需要进行调整
再次点击麦克风时关闭收音
自动静音后关闭麦克风（还有按钮）
下载好了FFmpeg7，等待更新，目前是4



（2025.04.09）
今日完成内容：
1.完成输入框和模型的关闭逻辑关联
2.完成鼠标滚轮缩放
遗留问题：
1.当模型放到过大或者过小的时候，对话框距离还是有点不合适，优先级：较低
2.在模型缩放过程中，会有一些抖动，有些影响感官，优先级：较低
正在进行内容：
创建后端服务器，将前端和后端连起来，仅使用一个main文件同时启动前后端，然后在前端对后端的asr模块进行测试，确保真正连通


（2025.04.08）
今日完成内容：
1.重构live2d窗口代码，建立父子窗口关系，为后续添加各种窗口提供便利
2.创建对话框窗口，在旁边加上语音输入和发送图标，完成一部分ui建设
3.锚定对话框与模型，能够跟随模型进行移动
4.创建调试功能，能够通过调试功能检查各窗口组件之间的层级关系和坐标位置
5.调整对话框初始化大小和后续增减文字的窗口变化情况
遗留问题：
1.表情切换还是没有实现，虽然已经有了初步思路，等待后续处理
2.输入框初始化后需要移动一次模型才能选中进行输入，算是一个小bug，但不影响使用，优先级：较低。
3.输入框在选中输入文字后高度会降低2px 目前原因未知，调试的时候输入框的坐标和高度都没有发生变化。怀疑是样式问题，全做完后再进行排查。算是一个可有可无的优化，优先级：极低
4.输入框在高度降低后会遮挡提示文字下面一小部分（如：请输入文字）目前原因未知，等后期排查优化，优先级：极低
后续功能安排：
1.明天首先将模型和输入框关闭逻辑相关联，实现关闭模型的同时关闭输入框
2.其次实现鼠标滚轮缩放功能，缩放的同时需要保持输入框的大小，距离不变
3.创建后端，将前后端打通，然后在后端连上asr模型，进行初步的接收声音-识别文字-文字输出测试




然后现在在用cursor从头开始一点点搞，先搞了live2d，然后后面的问题后面再说吧，先搞搞看看吧。





头都大了，搞了半天才发现那个倒霉玩意不是个开源的项目，想改都没法改，好吧，那就只能换个项目试试了。然后找了个项目更是大怨种，呀呀呸的写代码不写注释，是真的一点都看不懂，然后设置还难的跟鬼一样，一点都不好配置，可读性差的要死。用ai折腾了半天，辛辛苦苦把他的那些模型api转成了本地，然后搞了半天还没法用，响应慢的要命，最后算了，还是自己老老实实自己做吧



声音的敏感度不行，不知道是我没设置好还是怎么回事，更新到6.11然后再看看配置视频再说吧，实在不行的话收音模式也要更改才行


目前选择依赖项目七，在项目四的基础上进行调整
具体调整需要等下载下来后再做决定
至少需要的几个功能必须要有，具体功能参考readme
需要增加一个屏幕文字识别功能，然后进行点击。如：点击屏幕上的网易云音乐文字（支持点击，长按，双击等，识别完文字后，列出方框进行询问：已在屏幕上找到以下，请问你要选第几个？）


如果三个模型都部署在本机上，它们启动时都会提供一个端口号，然后就需要通过端口号进行数据交互，我们要做的就是写一个端口号间数据交互的脚本



现在开始全部推翻重新来
先来一波市场调研，然后再进行考察
项目一：
AI+live2d看板娘浏览器助手，实现模型切换和页面内容总结
开源地址：PublicLive2dPlug/PublicLive2dAIPlug at main · Vita0519/PublicLive2dPlug（github）
功能：live2d模型展示，只能页面总结，多模型支持，高度自定义，便捷操作，api设置

项目二：
Live2D For C++(Qt)实现二次元桌宠--BV1TtkHYpEDA
https://github.com/Misakiotoha/Live2D_For_C-Qt-OpenGL-

项目三：
【开源AI桌宠】你的下一个人工智能，何必是网页--BV1E3XWYMErS
开源地址：https://github.com/HeavyNotFat/Agentic-AI-Desktop-Pet
下载地址：https://github.com/HeavyNotFat/Agentic-AI-Desktop-Pet/releases
官网：http://nekocode.top
功能：live2d模型展示，ai语音（gsv），大语言模型，扩展接口

项目四：
【全球第一个AI-Agent桌宠】芙宁娜教你如何正确使用最强Agent桌宠--BV1nS42197pj
https://pan.quark.cn/s/dd6d8cc5f609
功能：聊天，问答，联网，live2d人物模型，执行计算机操作

项目五：
五分钟部署一个有长期记忆和表情动作ai桌宠，ZcChat安装教程2.0--BV1hA9SYYEbb
https://github.com/Zao-chen/ZcChat
功能：语音输入输出，语音唤醒，操控电脑，制作角色（只是jpg，不是live2d），自定义llm

项目六：
It's Agent Time! 你的本地智能代理人时间到 Nath UI 4.1 整合包 重磅更新--BV1259bYeE6P
优点：写论文的时候可以参考流程图和使用思路

项目七：
开源AI桌宠2.2更新，1分钟即可上手，手搓中文脚本给AI，让大模型做更多的事情，完成简易agent--BV1t8ePeBE2m
https://dd-mastert.github.io/2024/08/15/2024.8.15-2/
功能：可以参考他的电脑操作思路



安装 webrtcvad 疯狂出错，说是我本地没有能够编译的环境，搞了vs2019后还是不行
最后居然是在csdn上找到人家已经编译好了的包，然后直接解压缩到虚拟环境中解决的
那个编译好的包的下载地址还被墙了，就离谱
然后下载下来后发现还是跑不动，一查才发现要在电脑上编译一遍才行
后面重新下载了vs2022，用它专门那个x64 native什么的cmd才正常下载，重新编译成功了
然后才能正常使用




首先，做好了一个前后端，前端可以通过按钮发送请求给后端接受

语音输入：在前端添加麦克风输入功能，使用WebRTC捕获音频，并将音频数据发送到后端。
语音识别：在后端调用ASR模型，将音频数据转换为文本。
文本生成：在后端调用LLM模型，生成响应文本。
语音合成：在后端调用TTS模型，将文本转换为语音，并返回给前端播放。

失败，失败原因：阿里的asr模型没有下载部署，需要另行下载




我需要做一个基于Python的语音助手设计与实现，界面需要做成一个可以在电脑桌面上显示的live2D模型，
而且这个模型需要支持直接套用VTuberStudio的模型文件。右键这个桌面的live2D模型需要可以打开一个完整的设置界面。
其中使用ASR+LLM+TTS串联形式来搭建本地的语音交互助手，采用阿里开源SenceVoice作为ASR模型，tts需要使用GPT-SoVITS的模型。
后台需要可以接入部署在电脑上的第三方大语言模型比如说deepseek-r1:14b，或者ollama。帮我设计这个项目的技术架构




听了网友劝，不用pycharm了，用vscode试试




可以提供参考的项目
搭建自己的语音对话大模型 | ASR+LLM+TTS串联--------------https://github.com/ABexit/ASR-LLM-TTS
开发了一个越聊越懂你的AI女友 | 开源｜腾讯云AI代码助手----https://github.com/mewamew/nana
训练一个AI桌宠 创造出你喜欢的角色 你想做的，都能实现-----https://github.com/morettt/my-neuro
开源AI女友安装教学 [Open-LLM-VTuber v0.2.4]------------https://github.com/t41372/Open-LLM-VTuber





asr试了谷歌的，结果一直报错
语音服务请求失败：recognition connection failed: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。
一直连不上，问ai找解决方法也没找到，然后放弃了
然后跑去尝试离线的sphinx，但是发现这玩意不管是中文还是英文转化都有点大病，根本没法正常使用
然后打算试一下vosk，结果还没开始尝试，找到破站说阿里的比较好用
明天去试试阿里的这东西
而且在破站找了找才知道，像我现在看到一个就下一个依赖项是有那么点大病的，最好还是搞一个虚拟环境
我终于知道为啥我c盘会爆炸了，估计是之前搞的一堆乱七八糟的环境，然后还没清理那种
真得给这个鬼玩意安排一个虚拟环境





要下载以下第三方库，然后进行导入
pip install speechrecognition pyttsx3 pyautogui selenium flask sqlalchemy
pip install wolframalpha wikipedia winshell pyjokes twilio beautifulsoup4 tk

下载完成后验证一下
import speech_recognition as sr
import pyttsx3
import pyautogui
from selenium import webdriver
from flask import Flask
from sqlalchemy import create_engine
print("所有库导入成功！"